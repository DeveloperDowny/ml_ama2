{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dfhelper as dfh\n",
    "import text_preproc as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.read_pickle('dataset/train_df_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfh.printColNames(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marr = pre_df.columns.values\n",
    "\n",
    "title = marr[0]\n",
    "bull_pt = marr[1]\n",
    "desc = marr[2]\n",
    "prod_type_id= marr[3]\n",
    "prod_len = marr[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpy_df = pre_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_df = pre_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpy_df = pd.get_dummies(pre_df, columns=[prod_type_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpy_df\n",
    "cpy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_thousand = pre_df[:1000]\n",
    "first_thousand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     print(pre_df.iloc[i][\"TITLE\"])\n",
    "#     keyboard.wait('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdf = pre_df.drop(columns=['BULLET_POINTS', 'DESCRIPTION', 'PRODUCT_LENGTH'])\n",
    "# mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist = []\n",
    "# back prop\n",
    "# we are obviously smart\n",
    "# let's see how we predict and the try to extract\n",
    "# print all with prod_len between 0 and 100\n",
    "def printCountInGivenRange(pre_df, inr, outr):\n",
    "    count = 0\n",
    "    # for i in range(pre_df.shape[0]):\n",
    "    for i in range(1000):\n",
    "        if pre_df.iloc[i][prod_len] <= outr and pre_df.iloc[i][prod_len] >= inr:\n",
    "            count += 1\n",
    "            print(i, pre_df.iloc[i][prod_len], pre_df.iloc[i][title])\n",
    "            mlist.append(i)\n",
    "            num = \"\"\n",
    "            for j in pre_df.columns.values:\n",
    "                if (\"id\" in j.lower()):\n",
    "                    num += str(pre_df.iloc[i][j]) + \" \"\n",
    "            print(num)\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printCountInGivenRange(first_thousand, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printCountInGivenRange(first_thousand, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mrow = pre_df[prod_len]\n",
    "for i,v in first_thousand.iterrows():\n",
    "    if (v[prod_len] == 1885801400.0):\n",
    "        print(v[title])\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply put through lazy predict bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use cpy_df. First do splits and then use lazy predict\n",
    "# %pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lazypredict.Supervised import LazyClassifier\n",
    "# from sklearn.datasets import load_breast_cancer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data = load_breast_cancer()\n",
    "# X = data.data\n",
    "# y= data.target\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123)\n",
    "\n",
    "# clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "# models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "\n",
    "# Download the required NLTK resources\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove numbers and punctuation\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    lem = WordNetLemmatizer()\n",
    "    words = [lem.lemmatize(word, \"v\") for word in words]\n",
    "\n",
    "    # Join words back into a sentence\n",
    "    preprocessed_text = \" \".join(words)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "# Example usage:\n",
    "text = \"This is an example sentence. It will be used to demonstrate text preprocessing for Word2Vec.\"\n",
    "preprocessed_text = preprocess_text(text)\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data = pd.read_csv('your_data.csv')\n",
    "data = cpy_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop([prod_len], axis=1), data[prod_len], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and prepare word embeddings\n",
    "# w2v_model = Word2Vec.load('your_word_embeddings.model')\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe you need to pre process the data\n",
    "# maybe you need to use ann and tensorflow instead of sklearn\n",
    "m_word = X_train[title].values[0].split(\" \")[0]\n",
    "print(m_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model\n",
    "word = 'king'\n",
    "vector = w2v_model[m_word]\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.39459726 -0.785355   -0.3071021  ... -0.855016   -0.2719474\n",
      "    0.5896925 ]\n",
      "  [-0.74061793 -0.60996133 -0.5062999  ... -0.31280124  0.7690935\n",
      "    0.07103826]\n",
      "  [-0.36278898 -0.6912678   0.2634068  ... -0.07483993  0.523368\n",
      "    0.58124304]\n",
      "  ...\n",
      "  [ 0.2371747   0.26732197  0.37201953 ... -0.638582   -1.0357348\n",
      "    0.66088116]\n",
      "  [-0.30154967 -0.36846936 -0.00316174 ... -0.6946786  -0.73371553\n",
      "   -0.04277612]\n",
      "  [ 0.6092344  -0.1332865  -0.40263057 ...  0.23701602 -0.5503922\n",
      "    0.02643796]]], shape=(1, 19, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize input text and convert to TensorFlow tensors\n",
    "# text = \"This is an example sentence.\"\n",
    "text = \"This is an example sentence. Tokenize input text and convert to TensorFlow tensors \"\n",
    "# inputs = tokenizer(text, return_tensors='tf')\n",
    "inputs = tokenizer(text, return_tensors='tf', max_length=512, truncation=True)\n",
    "# inputs = tokenizer(text)\n",
    "\n",
    "# Pass input through the model to get the output vector\n",
    "# outputs = model(inputs)[0]\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Print the output vector\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(1, 19, 768), dtype=float32, numpy=\n",
      "array([[[-0.39459726, -0.785355  , -0.3071021 , ..., -0.855016  ,\n",
      "         -0.2719474 ,  0.5896925 ],\n",
      "        [-0.74061793, -0.60996133, -0.5062999 , ..., -0.31280124,\n",
      "          0.7690935 ,  0.07103826],\n",
      "        [-0.36278898, -0.6912678 ,  0.2634068 , ..., -0.07483993,\n",
      "          0.523368  ,  0.58124304],\n",
      "        ...,\n",
      "        [ 0.2371747 ,  0.26732197,  0.37201953, ..., -0.638582  ,\n",
      "         -1.0357348 ,  0.66088116],\n",
      "        [-0.30154967, -0.36846936, -0.00316174, ..., -0.6946786 ,\n",
      "         -0.73371553, -0.04277612],\n",
      "        [ 0.6092344 , -0.1332865 , -0.40263057, ...,  0.23701602,\n",
      "         -0.5503922 ,  0.02643796]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
      "array([[-0.73170996, -0.4720331 , -0.91274244,  0.5767257 ,  0.8155095 ,\n",
      "        -0.41480705,  0.5162307 ,  0.27219692, -0.8038374 , -0.9999446 ,\n",
      "        -0.48134282,  0.76201046,  0.94484943,  0.42327952,  0.6202101 ,\n",
      "        -0.5957338 ,  0.09234584, -0.6054795 ,  0.40471077,  0.28197154,\n",
      "         0.54335254,  0.9999943 , -0.09118145,  0.3781805 ,  0.5150067 ,\n",
      "         0.89939463, -0.62739795,  0.7949522 ,  0.8490342 ,  0.77763796,\n",
      "        -0.40665615,  0.245605  , -0.9842235 , -0.36644766, -0.9711022 ,\n",
      "        -0.9788375 ,  0.51252466, -0.56986326, -0.03163384,  0.05227435,\n",
      "        -0.8201826 ,  0.49633822,  0.99996704, -0.26783156,  0.70946866,\n",
      "        -0.31861928, -0.99999803,  0.35726717, -0.7514938 ,  0.88101965,\n",
      "         0.8386638 ,  0.8853865 ,  0.28204674,  0.41444162,  0.5560661 ,\n",
      "        -0.39120373, -0.03500376,  0.34762576, -0.2910547 , -0.5678042 ,\n",
      "        -0.55881315,  0.43188548, -0.778997  , -0.83304226,  0.8401112 ,\n",
      "         0.7788644 , -0.30049175, -0.45822537, -0.26411483, -0.03476597,\n",
      "         0.6348591 ,  0.3736467 , -0.2559769 , -0.73665285,  0.6862422 ,\n",
      "         0.41412064, -0.5849491 ,  1.        , -0.16843653, -0.94145817,\n",
      "         0.8957486 ,  0.7555432 ,  0.55569196, -0.37400317,  0.44202372,\n",
      "        -1.        ,  0.6266958 , -0.34566674, -0.96802855,  0.2611446 ,\n",
      "         0.57227445, -0.26963824,  0.87006456,  0.61851156, -0.58156335,\n",
      "        -0.6303882 , -0.3453381 , -0.87144387, -0.43025336, -0.6980992 ,\n",
      "         0.30116445, -0.4039679 , -0.4185426 , -0.39821744,  0.47861895,\n",
      "        -0.39844525, -0.03423958,  0.7544405 ,  0.28271064,  0.6548943 ,\n",
      "         0.53671044, -0.42214343,  0.4574808 , -0.79278445,  0.5898895 ,\n",
      "        -0.5345443 , -0.97358805, -0.61645854, -0.9636058 ,  0.7011248 ,\n",
      "        -0.17200626, -0.4763784 ,  0.7777856 , -0.5382097 ,  0.4295101 ,\n",
      "        -0.17971663, -0.8983195 , -1.        , -0.49537376, -0.7822901 ,\n",
      "        -0.17935747, -0.35556093, -0.950591  , -0.9167794 ,  0.7194604 ,\n",
      "         0.9199454 ,  0.292423  ,  0.999806  , -0.32940894,  0.8582393 ,\n",
      "        -0.16928576, -0.7051414 ,  0.44355485, -0.41363707,  0.88616765,\n",
      "         0.02144779, -0.69215333,  0.21341464, -0.50277716,  0.27187702,\n",
      "        -0.6328438 , -0.30158216, -0.7903666 , -0.768635  , -0.32029566,\n",
      "         0.7888112 , -0.63401407, -0.90678877, -0.03547323, -0.10164282,\n",
      "        -0.40070334,  0.79009014,  0.7792891 ,  0.2464617 , -0.38481197,\n",
      "         0.50932336, -0.02060736,  0.60011065, -0.74163723,  0.0984716 ,\n",
      "         0.49969324, -0.36501348, -0.9256048 , -0.9574505 , -0.39320138,\n",
      "         0.37559715,  0.95646834,  0.59590966,  0.551029  ,  0.6378655 ,\n",
      "        -0.45402795,  0.43989235, -0.9121107 ,  0.96348935, -0.13596587,\n",
      "         0.31775084, -0.7191531 ,  0.69753   , -0.73994327,  0.25337625,\n",
      "         0.61798126, -0.65995246, -0.7776837 , -0.15761071, -0.58905536,\n",
      "        -0.50543183, -0.8710191 ,  0.51872367, -0.5289276 , -0.5509547 ,\n",
      "        -0.15686488,  0.8384165 ,  0.8764678 ,  0.34115425,  0.5060375 ,\n",
      "         0.60621214, -0.6323423 , -0.26383632,  0.1810443 ,  0.30259922,\n",
      "         0.2688187 ,  0.9762629 , -0.8544469 , -0.23757203, -0.7463576 ,\n",
      "        -0.9108592 , -0.08900764, -0.63073283, -0.29557166, -0.72123253,\n",
      "         0.68382937, -0.74202377,  0.3600308 ,  0.28095856, -0.62940896,\n",
      "        -0.7062112 ,  0.38805375, -0.5865529 ,  0.5551252 , -0.37665233,\n",
      "         0.9666802 ,  0.9442385 , -0.708113  , -0.24044251,  0.96694994,\n",
      "        -0.89156014, -0.801058  ,  0.41379204, -0.35697877,  0.7484123 ,\n",
      "        -0.68031114,  0.9752902 ,  0.8599409 ,  0.15538332, -0.68016756,\n",
      "        -0.7930025 , -0.66285515, -0.41077515, -0.3675309 ,  0.08600976,\n",
      "         0.8555311 ,  0.66166025,  0.37124196,  0.04998538, -0.47181523,\n",
      "         0.87446487, -0.9691843 , -0.9103177 , -0.8847536 , -0.18331763,\n",
      "        -0.9773092 ,  0.85863537,  0.32048333,  0.85749954, -0.58275914,\n",
      "        -0.52495104, -0.92701787,  0.630745  ,  0.0912448 ,  0.89560616,\n",
      "        -0.64286727, -0.6923648 , -0.70386326, -0.8812756 , -0.04601041,\n",
      "        -0.26237684, -0.3830732 ,  0.0468626 , -0.7518557 ,  0.5619608 ,\n",
      "         0.5818988 ,  0.39171302, -0.88167673,  0.9735478 ,  1.        ,\n",
      "         0.92232764,  0.57393223,  0.3678441 , -0.9999164 , -0.8791192 ,\n",
      "         0.9999789 , -0.982193  , -1.        , -0.8399109 , -0.56774664,\n",
      "         0.3015236 , -1.        , -0.30591366, -0.06154797, -0.6597626 ,\n",
      "         0.5994066 ,  0.93780935,  0.82467705, -1.        ,  0.74199754,\n",
      "         0.7469591 , -0.6177952 ,  0.7946085 , -0.5666528 ,  0.915317  ,\n",
      "         0.58643967,  0.60906637, -0.2604231 ,  0.55314153, -0.9510837 ,\n",
      "        -0.7251514 , -0.77041566, -0.81513214,  0.99930793,  0.24641094,\n",
      "        -0.7582213 , -0.58882016,  0.6577314 ,  0.02343299,  0.02904486,\n",
      "        -0.8665254 , -0.45025584,  0.15996018,  0.6580619 ,  0.38592795,\n",
      "         0.30048347, -0.34560695,  0.45246026,  0.42917526, -0.05728802,\n",
      "         0.6340731 , -0.8367812 , -0.03870686, -0.39755446,  0.13358146,\n",
      "        -0.6967032 , -0.96273476,  0.8722025 , -0.4241012 ,  0.7941985 ,\n",
      "         1.        ,  0.74230605, -0.5513154 ,  0.6551054 ,  0.327943  ,\n",
      "        -0.74448484,  1.        ,  0.78386813, -0.9497034 , -0.53105223,\n",
      "         0.74392855, -0.6721514 , -0.6750555 ,  0.99854106, -0.27443838,\n",
      "        -0.7488478 , -0.5235625 ,  0.9725552 , -0.98385704,  0.9978799 ,\n",
      "        -0.43143925, -0.9192405 ,  0.8739983 ,  0.8221407 , -0.4113489 ,\n",
      "        -0.79437816,  0.0373634 , -0.6638886 ,  0.28575587, -0.69320494,\n",
      "         0.47203192,  0.35145566, -0.09851199,  0.73750955, -0.15470606,\n",
      "        -0.63476443,  0.47464174, -0.5529392 ,  0.06699354,  0.9395647 ,\n",
      "         0.47392318, -0.44110155,  0.01344374, -0.34350586, -0.73953044,\n",
      "        -0.8769651 ,  0.7183967 ,  1.        , -0.16913955,  0.7887963 ,\n",
      "        -0.12693498, -0.2705061 ,  0.21490927,  0.59803647,  0.6856946 ,\n",
      "        -0.38882777, -0.6927732 ,  0.76972127, -0.61069626, -0.9793594 ,\n",
      "         0.278219  ,  0.21894717, -0.28880638,  0.9999379 ,  0.42268968,\n",
      "         0.3469068 ,  0.5389036 ,  0.9408891 ,  0.18074015,  0.1004642 ,\n",
      "         0.85593736,  0.9675309 , -0.37633613,  0.6289627 ,  0.3960846 ,\n",
      "        -0.8605628 , -0.36812723, -0.66048807,  0.23729792, -0.94214123,\n",
      "        -0.19248344, -0.88198346,  0.94089514,  0.88718694,  0.36714065,\n",
      "         0.3747351 ,  0.90385073,  1.        , -0.9442867 ,  0.48155728,\n",
      "         0.4515743 ,  0.2084143 , -0.9998826 , -0.26644677, -0.41867122,\n",
      "        -0.14262682, -0.78045386, -0.32939553,  0.24461764, -0.93483365,\n",
      "         0.81410503,  0.61966074, -0.853304  , -0.9288046 , -0.4100549 ,\n",
      "         0.4635442 ,  0.14180069, -0.9909689 , -0.3697518 , -0.4678459 ,\n",
      "         0.61317956, -0.50428444, -0.7603769 , -0.333277  , -0.48219556,\n",
      "         0.43292275, -0.46071258,  0.6765828 ,  0.8936877 ,  0.79051745,\n",
      "        -0.9649355 , -0.36421368, -0.21167126, -0.727683  ,  0.46036983,\n",
      "        -0.6625108 , -0.91058415, -0.28401142,  1.        , -0.4367845 ,\n",
      "         0.912284  ,  0.4132784 ,  0.54546416, -0.29014018,  0.3383457 ,\n",
      "         0.9630141 ,  0.30957648, -0.5278907 , -0.85818505,  0.3910326 ,\n",
      "        -0.4566577 ,  0.6510279 ,  0.741977  ,  0.6546915 ,  0.6399506 ,\n",
      "         0.90172803,  0.24440719, -0.20766401,  0.0772356 ,  0.95348155,\n",
      "        -0.27165338, -0.31354383, -0.51950836, -0.37080222, -0.32576853,\n",
      "         0.35481897,  1.        ,  0.3613931 ,  0.6710473 , -0.9721044 ,\n",
      "        -0.7998194 , -0.67144936,  1.        ,  0.74883455, -0.52210903,\n",
      "         0.7052476 ,  0.4053784 , -0.17059204,  0.38134104, -0.4180125 ,\n",
      "        -0.36339393,  0.25858107,  0.13787991,  0.83469015, -0.50894177,\n",
      "        -0.9542097 , -0.73844427,  0.37424076, -0.89948666,  0.99996555,\n",
      "        -0.6809049 , -0.24689806, -0.27615   , -0.35762075, -0.6255038 ,\n",
      "         0.10419416, -0.89958405, -0.2988065 ,  0.30771175,  0.88486445,\n",
      "         0.46571526, -0.5394804 , -0.84965897,  0.82968694,  0.7194026 ,\n",
      "        -0.8261502 , -0.8341965 ,  0.88695353, -0.85942066,  0.47579324,\n",
      "         1.        ,  0.58306897,  0.20566432,  0.20691939, -0.34442338,\n",
      "         0.37768668, -0.6811667 ,  0.29786402, -0.86456394, -0.4586445 ,\n",
      "        -0.3571837 ,  0.39966303, -0.26540354, -0.75245255,  0.27568722,\n",
      "         0.41591904, -0.55109787, -0.51129884, -0.3427187 ,  0.30050066,\n",
      "         0.6247812 , -0.27412492, -0.3207999 ,  0.19961432, -0.28360742,\n",
      "        -0.6003596 , -0.4575206 , -0.60657865, -0.9999967 ,  0.65644383,\n",
      "        -1.        ,  0.6190375 ,  0.16651596, -0.2563708 ,  0.81871766,\n",
      "         0.7345353 ,  0.6763649 , -0.45993719, -0.85213375,  0.24310279,\n",
      "         0.53763187, -0.3924459 , -0.10985786, -0.43570173,  0.40216675,\n",
      "        -0.1222258 ,  0.30329794, -0.6827496 ,  0.787395  , -0.26597315,\n",
      "         1.        ,  0.16999863, -0.585567  , -0.7007337 ,  0.3930763 ,\n",
      "        -0.39608163,  1.        , -0.62160265, -0.92222553,  0.3419485 ,\n",
      "        -0.77041537, -0.7645043 ,  0.44118398,  0.25421628, -0.65630805,\n",
      "        -0.939741  ,  0.59729743,  0.6593889 , -0.5324886 ,  0.5616037 ,\n",
      "        -0.33541974, -0.45768452,  0.26951817,  0.89121085,  0.9635906 ,\n",
      "         0.6662586 ,  0.76088494, -0.50721145, -0.44703728,  0.91612977,\n",
      "         0.4776211 , -0.20544009,  0.19705325,  1.        ,  0.43299434,\n",
      "        -0.8904003 , -0.20834683, -0.879222  , -0.39965716, -0.8111633 ,\n",
      "         0.35135105,  0.47537345,  0.83348507, -0.45864704,  0.84283185,\n",
      "        -0.8569278 ,  0.17596872, -0.37532517, -0.5653065 ,  0.31297883,\n",
      "        -0.77166   , -0.9579227 , -0.9557342 ,  0.63501716, -0.46516386,\n",
      "        -0.281966  ,  0.29332942,  0.13993904,  0.43803468,  0.39295098,\n",
      "        -1.        ,  0.884662  ,  0.50617826,  0.81707335,  0.86993706,\n",
      "         0.49470243,  0.7063158 ,  0.28629264, -0.9563656 , -0.54307187,\n",
      "        -0.45631853, -0.48129407,  0.61061645,  0.73832804,  0.724594  ,\n",
      "         0.33476785, -0.5402253 , -0.56702393, -0.71379304, -0.90620667,\n",
      "        -0.9795066 ,  0.5127403 , -0.5518413 , -0.6203578 ,  0.9355226 ,\n",
      "         0.15838628, -0.15287952, -0.08862156, -0.86680776,  0.32997313,\n",
      "         0.4750559 ,  0.30249768,  0.04133726,  0.5889158 ,  0.6350887 ,\n",
      "         0.8600345 ,  0.9546323 , -0.839234  ,  0.5096102 , -0.67420727,\n",
      "         0.53746235,  0.9367465 , -0.9385666 ,  0.40696126,  0.76573294,\n",
      "        -0.2894386 ,  0.21425633, -0.3638236 , -0.62152326,  0.9154173 ,\n",
      "        -0.37530842,  0.38439438, -0.4940371 ,  0.00317302, -0.4689607 ,\n",
      "        -0.30108312, -0.7656567 , -0.41262168,  0.5812462 ,  0.18445052,\n",
      "         0.7944319 ,  0.8681156 , -0.15618609, -0.60781056, -0.24812137,\n",
      "        -0.62006664, -0.9070496 ,  0.64807934, -0.08188179, -0.25674593,\n",
      "         0.8492121 ,  0.02533281,  0.96474147,  0.47380596, -0.43992183,\n",
      "        -0.2810424 , -0.7811143 ,  0.53722566, -0.72957176, -0.7084345 ,\n",
      "        -0.43446156,  0.59904575,  0.44229367,  0.9999962 , -0.8051921 ,\n",
      "        -0.79572767, -0.72855484, -0.39408705,  0.56765157, -0.5437616 ,\n",
      "        -1.        ,  0.49307537, -0.5348864 ,  0.7284386 , -0.6057392 ,\n",
      "         0.8506475 , -0.45325926, -0.86724997, -0.3895385 ,  0.82501656,\n",
      "         0.7544245 , -0.40905827, -0.34209624,  0.4410613 ,  0.02922301,\n",
      "         0.9506386 ,  0.5910076 , -0.5866944 , -0.09593567,  0.6246278 ,\n",
      "        -0.93288094, -0.62800103,  0.6881092 ]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# Example list of texts\n",
    "# texts = ['This is the first text.', 'This is the second text.', 'This is the third text.']\n",
    "texts = [\"HACASO - The Princess Sleeps Here- Pink Wall Decal Girl's Bedroom Decor\", 'PINKCITY CREATION Handmade Showpieces Figurine Fluorite Stone Religious Idol Ganesha 5 cm.', 'Lovely Furniture Floating Mounted Cube Shape Wall Shelves Set of 4 (Black)']\n",
    "\n",
    "# Tokenize the texts\n",
    "# tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "outputs = model(inputs)\n",
    "# Print the tokenized texts\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = X_train[title].values[0]\n",
    "text = X_train[title].values[0:3].tolist()\n",
    "print(type(text))\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(text, return_tensors='tf')\n",
    "inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
    "# inputs = tokenizer(text)\n",
    "\n",
    "# Pass input through the model to get the output vector\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Print the output vector\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert output tensor to numpy array\n",
    "output_array = outputs.numpy()\n",
    "\n",
    "# Flatten and reshape the output array to match sklearn input format\n",
    "output_array = output_array.flatten().reshape(1, -1)\n",
    "\n",
    "# Print the output array\n",
    "print(output_array)\n",
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msent = preprocess_text(msent)\n",
    "print(msent)\n",
    "msent = msent.split(\" \")\n",
    "print(msent)\n",
    "# msent = [w2v_model[w] for w in msent]\n",
    "msent2 = []\n",
    "for i in msent:\n",
    "    try:\n",
    "        msent2.append(w2v_model[i])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(i)\n",
    "\n",
    "print(msent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msent = preprocess_text(msent)\n",
    "print(msent)\n",
    "msent = msent.split(\" \")\n",
    "print(msent)\n",
    "# msent = [w2v_model[w] for w in msent]\n",
    "msent2 = []\n",
    "for i in msent:\n",
    "    try:\n",
    "        msent2.append(w2v_model[i])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(i)\n",
    "\n",
    "print(msent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_embeddings = [w2v_model.wv[word] for word in X_train[title]]\n",
    "X_test_embeddings = [w2v_model.wv[word] for word in X_test[title]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_embeddings2 = [w2v_model.wv[word] for word in X_train[desc]]\n",
    "X_test_embeddings2 = [w2v_model.wv[word] for word in X_test[desc]]\n",
    "\n",
    "# Merge embeddings with other features\n",
    "X_train_final = pd.concat([X_train.drop([title], axis=1), pd.DataFrame(X_train_embeddings)], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop([title], axis=1), pd.DataFrame(X_test_embeddings)], axis=1)\n",
    "\n",
    "# Merge embeddings with other features\n",
    "X_train_final = pd.concat([X_train.drop([desc], axis=1), pd.DataFrame(X_train_embeddings2)], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop([desc], axis=1), pd.DataFrame(X_test_embeddings2)], axis=1)\n",
    "\n",
    "# Use Lazy Predict\n",
    "clf = LazyClassifier(verbose=2,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train_final, X_test_final, y_train, y_test)\n",
    "\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_embeddings2 = [w2v_model.wv[word] for word in X_train[desc]]\n",
    "X_test_embeddings2 = [w2v_model.wv[word] for word in X_test[desc]]\n",
    "\n",
    "# Merge embeddings with other features\n",
    "X_train_final = pd.concat([X_train.drop([title], axis=1), pd.DataFrame(X_train_embeddings)], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop([title], axis=1), pd.DataFrame(X_test_embeddings)], axis=1)\n",
    "\n",
    "# Merge embeddings with other features\n",
    "X_train_final = pd.concat([X_train.drop([desc], axis=1), pd.DataFrame(X_train_embeddings2)], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop([desc], axis=1), pd.DataFrame(X_test_embeddings2)], axis=1)\n",
    "\n",
    "# Use Lazy Predict\n",
    "clf = LazyClassifier(verbose=2,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train_final, X_test_final, y_train, y_test)\n",
    "\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtokenize2(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "    outputs = model(inputs)\n",
    "  \n",
    "    return outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtokenize(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    output_array = outputs[0].numpy()\n",
    "\n",
    "    # Flatten and reshape the output array to match sklearn input format\n",
    "    output_array = output_array.flatten().reshape(1, -1)\n",
    "    \n",
    "    # return outputs[0]\n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"HACASO - The Princess Sleeps Here- Pink Wall Decal Girl's Bedroom Decor\", 'PINKCITY CREATION Handmade Showpieces Figurine Fluorite Stone Religious Idol Ganesha 5 cm.', 'Lovely Furniture Floating Mounted Cube Shape Wall Shelves Set of 4 (Black)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.43380743 -0.594643    0.07364444 ...  0.36776006 -0.38914543\n",
      "  -0.22698034]]\n",
      "(1, 15360)\n",
      "tf.Tensor(\n",
      "[[[-0.43380743 -0.594643    0.07364444 ... -0.05213424  0.12490535\n",
      "    0.42825395]\n",
      "  [-0.10545568 -1.6703563   0.23767257 ... -0.11654496  0.26866344\n",
      "    0.2958064 ]\n",
      "  [-1.2422262  -0.7605037   0.44002134 ... -0.5697189   0.00459877\n",
      "   -0.8156161 ]\n",
      "  ...\n",
      "  [ 0.84935945  0.1251586  -0.13403404 ... -0.15713198 -0.01781187\n",
      "   -0.42972186]\n",
      "  [ 0.5802119   0.4472033   0.36661974 ... -0.422646   -0.44749838\n",
      "    0.26063016]\n",
      "  [ 0.6544737  -0.28135595 -0.01946732 ...  0.36776006 -0.38914543\n",
      "   -0.22698034]]], shape=(1, 20, 768), dtype=float32)\n",
      "(1, 20, 768)\n",
      "[[-0.6215099  -0.28986043 -0.10749999 ...  0.07650582 -0.29404986\n",
      "  -0.18917343]]\n",
      "(1, 19200)\n",
      "tf.Tensor(\n",
      "[[[-0.6215099  -0.28986043 -0.10749999 ... -0.18282071  0.21790671\n",
      "    0.22730517]\n",
      "  [ 0.12478697 -0.65829     0.46100584 ... -0.15136173  0.38925788\n",
      "   -0.48844454]\n",
      "  [ 0.42804483 -0.8235196   0.26472005 ... -0.19160193 -0.11209712\n",
      "   -0.3533564 ]\n",
      "  ...\n",
      "  [-0.32878742  0.2666189   0.48094893 ...  0.3347857   0.31943265\n",
      "   -0.59002346]\n",
      "  [-0.9304032  -0.7711936  -0.15577562 ...  0.9289917   0.41176516\n",
      "   -0.5772157 ]\n",
      "  [ 0.52857214  0.02144302 -0.1919864  ...  0.07650582 -0.29404986\n",
      "   -0.18917343]]], shape=(1, 25, 768), dtype=float32)\n",
      "(1, 25, 768)\n",
      "[[-0.30718356 -0.40588695  0.08126795 ...  0.10260057 -0.3321899\n",
      "  -0.12846392]]\n",
      "(1, 12288)\n",
      "tf.Tensor(\n",
      "[[[-0.30718356 -0.40588695  0.08126795 ... -0.3722728  -0.14332779\n",
      "    0.16954601]\n",
      "  [ 0.24896242 -0.01454199  0.19091892 ... -0.20970426  0.6519544\n",
      "   -0.22879235]\n",
      "  [ 0.8071861   0.5576926   0.48804742 ... -0.43329954  0.14543906\n",
      "   -0.6844454 ]\n",
      "  ...\n",
      "  [ 0.80603266 -0.39736235  0.6567605  ... -0.3067291  -0.07460585\n",
      "   -0.15235534]\n",
      "  [-0.33992502 -0.8013733   0.24089928 ... -0.43463084  0.22088993\n",
      "   -0.18800819]\n",
      "  [ 0.53825414 -0.07817107  0.00321075 ...  0.10260057 -0.3321899\n",
      "   -0.12846392]]], shape=(1, 16, 768), dtype=float32)\n",
      "(1, 16, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in texts:\n",
    "    print(mtokenize(i))\n",
    "    print(mtokenize(i).shape)\n",
    "\n",
    "    print(mtokenize2(i))\n",
    "    print(mtokenize2(i).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35298762,  0.02311424,  0.06549785, ..., -0.0628305 ,\n",
       "        -0.7847901 , -0.30727923]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtokenize(\"hansco this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtokenize(\"hansco this\")[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
