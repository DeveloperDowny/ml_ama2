{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dfhelper as dfh\n",
    "import text_preproc as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.read_pickle('dataset/train_df_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # taking only first thousand entries\n",
    "# pre_df = pre_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 TITLE | 1 BULLET_POINTS | 2 DESCRIPTION | 3 PRODUCT_TYPE_ID | 4 PRODUCT_LENGTH | "
     ]
    }
   ],
   "source": [
    "dfh.printColNames(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "marr = pre_df.columns.values\n",
    "\n",
    "title = marr[0]\n",
    "bull_pt = marr[1]\n",
    "desc = marr[2]\n",
    "prod_type_id= marr[3]\n",
    "prod_len = marr[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpy_df = pre_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_df = pre_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpy_df = pd.get_dummies(pre_df, columns=[prod_type_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1622)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpy_df\n",
    "cpy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1896156</th>\n",
       "      <td>Bildos 3Ply Non-Woven Fabric Disposable Surgic...</td>\n",
       "      <td>[Care Instructions: Non Washable,Mask Has 3 La...</td>\n",
       "      <td>Face masks may also be called isolation, laser...</td>\n",
       "      <td>12591</td>\n",
       "      <td>669.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715725</th>\n",
       "      <td>Negaor 10 PCS Interior Door Card Trim Panel Re...</td>\n",
       "      <td>[* Interior door card trim panel clips fastene...</td>\n",
       "      <td>Please check the Manufacturer Part Number and ...</td>\n",
       "      <td>7305</td>\n",
       "      <td>314.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229576</th>\n",
       "      <td>Madden Girl Women's Domain Boot, Black Fabric,...</td>\n",
       "      <td>Chukka-inspired boot with four-eye lacing syst...</td>\n",
       "      <td>Suede wedge laceup bootie</td>\n",
       "      <td>3293</td>\n",
       "      <td>500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670308</th>\n",
       "      <td>Patel's Velocity perfume (60ml)(pack of 1)</td>\n",
       "      <td>[Long Lasting Fragrances,Made From Real and Na...</td>\n",
       "      <td>Patel's Velocity Perfume is Long Lasting Perfu...</td>\n",
       "      <td>254</td>\n",
       "      <td>157.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945067</th>\n",
       "      <td>WorldCare® 1000W Car Power ply Output Socket U...</td>\n",
       "      <td>[New &amp; Imported Item,Delivers within 3 to 5 we...</td>\n",
       "      <td>WorldCare 1000W Car Power ply Output Socket US...</td>\n",
       "      <td>2087</td>\n",
       "      <td>590.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165557</th>\n",
       "      <td>Meenu Arts Flash X Hazard Module, Blinker/Flas...</td>\n",
       "      <td>[Plug N Play, 60 Patterns, No Switch Requried,...</td>\n",
       "      <td>FLASHER</td>\n",
       "      <td>7989</td>\n",
       "      <td>787.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497881</th>\n",
       "      <td>Leveret Fleece Mens Sleep Pants Elephant Small</td>\n",
       "      <td>[100% Micro Fleece Polyester,All styles are ma...</td>\n",
       "      <td>You'll love these comfy fleece sleep pants fro...</td>\n",
       "      <td>2842</td>\n",
       "      <td>600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511844</th>\n",
       "      <td>StaySoft Polarized Replacement Lenses for Oakl...</td>\n",
       "      <td>[Perfect Outdoor Goods - For golf, cycling, ru...</td>\n",
       "      <td>&lt;b&gt;Stay here, Keep Soft!&lt;/b&gt;&lt;br&gt;&lt;br&gt; That's St...</td>\n",
       "      <td>2799</td>\n",
       "      <td>400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189620</th>\n",
       "      <td>GRAFIQE Back Cover for ViVO Y20A V2052 Itachi ...</td>\n",
       "      <td>[GRAFIQE BACK COVER Great print Quality gives ...</td>\n",
       "      <td>Vivo Y20A Back Cover by GRAFIQE Stylish, Ultra...</td>\n",
       "      <td>12057</td>\n",
       "      <td>236.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504894</th>\n",
       "      <td>Crazy Dog Tshirts The Element of Surprise T Sh...</td>\n",
       "      <td>[Exclusive Crazy Dog T-shirt branded tee desig...</td>\n",
       "      <td>Be sure to get your daily dose of surprise...s...</td>\n",
       "      <td>2850</td>\n",
       "      <td>900.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     TITLE  \\\n",
       "1896156  Bildos 3Ply Non-Woven Fabric Disposable Surgic...   \n",
       "1715725  Negaor 10 PCS Interior Door Card Trim Panel Re...   \n",
       "229576   Madden Girl Women's Domain Boot, Black Fabric,...   \n",
       "670308          Patel's Velocity perfume (60ml)(pack of 1)   \n",
       "945067   WorldCare® 1000W Car Power ply Output Socket U...   \n",
       "...                                                    ...   \n",
       "165557   Meenu Arts Flash X Hazard Module, Blinker/Flas...   \n",
       "1497881     Leveret Fleece Mens Sleep Pants Elephant Small   \n",
       "1511844  StaySoft Polarized Replacement Lenses for Oakl...   \n",
       "189620   GRAFIQE Back Cover for ViVO Y20A V2052 Itachi ...   \n",
       "1504894  Crazy Dog Tshirts The Element of Surprise T Sh...   \n",
       "\n",
       "                                             BULLET_POINTS  \\\n",
       "1896156  [Care Instructions: Non Washable,Mask Has 3 La...   \n",
       "1715725  [* Interior door card trim panel clips fastene...   \n",
       "229576   Chukka-inspired boot with four-eye lacing syst...   \n",
       "670308   [Long Lasting Fragrances,Made From Real and Na...   \n",
       "945067   [New & Imported Item,Delivers within 3 to 5 we...   \n",
       "...                                                    ...   \n",
       "165557   [Plug N Play, 60 Patterns, No Switch Requried,...   \n",
       "1497881  [100% Micro Fleece Polyester,All styles are ma...   \n",
       "1511844  [Perfect Outdoor Goods - For golf, cycling, ru...   \n",
       "189620   [GRAFIQE BACK COVER Great print Quality gives ...   \n",
       "1504894  [Exclusive Crazy Dog T-shirt branded tee desig...   \n",
       "\n",
       "                                               DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "1896156  Face masks may also be called isolation, laser...            12591   \n",
       "1715725  Please check the Manufacturer Part Number and ...             7305   \n",
       "229576                           Suede wedge laceup bootie             3293   \n",
       "670308   Patel's Velocity Perfume is Long Lasting Perfu...              254   \n",
       "945067   WorldCare 1000W Car Power ply Output Socket US...             2087   \n",
       "...                                                    ...              ...   \n",
       "165557                                             FLASHER             7989   \n",
       "1497881  You'll love these comfy fleece sleep pants fro...             2842   \n",
       "1511844  <b>Stay here, Keep Soft!</b><br><br> That's St...             2799   \n",
       "189620   Vivo Y20A Back Cover by GRAFIQE Stylish, Ultra...            12057   \n",
       "1504894  Be sure to get your daily dose of surprise...s...             2850   \n",
       "\n",
       "         PRODUCT_LENGTH  \n",
       "1896156          669.29  \n",
       "1715725          314.96  \n",
       "229576           500.00  \n",
       "670308           157.48  \n",
       "945067           590.55  \n",
       "...                 ...  \n",
       "165557           787.40  \n",
       "1497881          600.00  \n",
       "1511844          400.00  \n",
       "189620           236.22  \n",
       "1504894          900.00  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_thousand = pre_df[:1000]\n",
    "first_thousand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     print(pre_df.iloc[i][\"TITLE\"])\n",
    "#     keyboard.wait('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdf = pre_df.drop(columns=['BULLET_POINTS', 'DESCRIPTION', 'PRODUCT_LENGTH'])\n",
    "# mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist = []\n",
    "# back prop\n",
    "# we are obviously smart\n",
    "# let's see how we predict and the try to extract\n",
    "# print all with prod_len between 0 and 100\n",
    "def printCountInGivenRange(pre_df, inr, outr):\n",
    "    count = 0\n",
    "    # for i in range(pre_df.shape[0]):\n",
    "    for i in range(1000):\n",
    "        if pre_df.iloc[i][prod_len] <= outr and pre_df.iloc[i][prod_len] >= inr:\n",
    "            count += 1\n",
    "            print(i, pre_df.iloc[i][prod_len], pre_df.iloc[i][title])\n",
    "            mlist.append(i)\n",
    "            num = \"\"\n",
    "            for j in pre_df.columns.values:\n",
    "                if (\"id\" in j.lower()):\n",
    "                    num += str(pre_df.iloc[i][j]) + \" \"\n",
    "            print(num)\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printCountInGivenRange(first_thousand, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printCountInGivenRange(first_thousand, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_mrow = pre_df[prod_len]\n",
    "# for i,v in first_thousand.iterrows():\n",
    "#     if (v[prod_len] == 1885801400.0):\n",
    "#         print(v[title])\n",
    "#         print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply put through lazy predict bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use cpy_df. First do splits and then use lazy predict\n",
    "# %pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lazypredict.Supervised import LazyClassifier\n",
    "# from sklearn.datasets import load_breast_cancer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data = load_breast_cancer()\n",
    "# X = data.data\n",
    "# y= data.target\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123)\n",
    "\n",
    "# clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "# models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import gensim\n",
    "# from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import string\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# import gensim\n",
    "\n",
    "# # Download the required NLTK resources\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     # Convert text to lowercase\n",
    "#     text = text.lower()\n",
    "\n",
    "#     # Remove numbers and punctuation\n",
    "#     text = re.sub(r'\\d+', '', text)\n",
    "#     text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "#     # Tokenize text into words\n",
    "#     words = word_tokenize(text)\n",
    "\n",
    "#     # Remove stop words\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     words = [word for word in words if word not in stop_words]\n",
    "\n",
    "#     # Lemmatize words\n",
    "#     lem = WordNetLemmatizer()\n",
    "#     words = [lem.lemmatize(word, \"v\") for word in words]\n",
    "\n",
    "#     # Join words back into a sentence\n",
    "#     preprocessed_text = \" \".join(words)\n",
    "\n",
    "#     return preprocessed_text\n",
    "\n",
    "# # Example usage:\n",
    "# text = \"This is an example sentence. It will be used to demonstrate text preprocessing for Word2Vec.\"\n",
    "# preprocessed_text = preprocess_text(text)\n",
    "# print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data = pd.read_csv('your_data.csv')\n",
    "data = cpy_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load and prepare word embeddings\n",
    "# # w2v_model = Word2Vec.load('your_word_embeddings.model')\n",
    "# w2v_model = gensim.models.KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maybe you need to pre process the data\n",
    "# # maybe you need to use ann and tensorflow instead of sklearn\n",
    "# m_word = X_train[title].values[0].split(\" \")[0]\n",
    "# print(m_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model\n",
    "# word = 'king'\n",
    "# vector = w2v_model[m_word]\n",
    "# print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModel.from_pretrained(model_name)\n",
    "\n",
    "# (batch_size, sequence_length, hidden_size) token ka embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Tokenize input text and convert to TensorFlow tensors\n",
    "# # text = \"This is an example sentence.\"\n",
    "# text = \"This is an example sentence. Tokenize input text and convert to TensorFlow tensors \"\n",
    "# # inputs = tokenizer(text, return_tensors='tf')\n",
    "# inputs = tokenizer(text, return_tensors='tf', max_length=512, truncation=True)\n",
    "# # inputs = tokenizer(text)\n",
    "\n",
    "# # Pass input through the model to get the output vector\n",
    "# # outputs = model(inputs)[0]\n",
    "# outputs = model(inputs)\n",
    "\n",
    "# # Print the output vector\n",
    "# print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example list of texts\n",
    "# # texts = ['This is the first text.', 'This is the second text.', 'This is the third text.']\n",
    "# texts = [\"HACASO - The Princess Sleeps Here- Pink Wall Decal Girl's Bedroom Decor\", 'PINKCITY CREATION Handmade Showpieces Figurine Fluorite Stone Religious Idol Ganesha 5 cm.', 'Lovely Furniture Floating Mounted Cube Shape Wall Shelves Set of 4 (Black)']\n",
    "\n",
    "# # Tokenize the texts\n",
    "# # tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "# tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "# outputs = model(inputs)\n",
    "# # Print the tokenized texts\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # text = X_train[title].values[0]\n",
    "# text = X_train[title].values[0:3].tolist()\n",
    "# print(type(text))\n",
    "# print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inputs = tokenizer(text, return_tensors='tf')\n",
    "# inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
    "# # inputs = tokenizer(text)\n",
    "\n",
    "# # Pass input through the model to get the output vector\n",
    "# outputs = model(inputs)\n",
    "\n",
    "# # Print the output vector\n",
    "# print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert output tensor to numpy array\n",
    "# output_array = outputs.numpy()\n",
    "\n",
    "# # Flatten and reshape the output array to match sklearn input format\n",
    "# output_array = output_array.flatten().reshape(1, -1)\n",
    "\n",
    "# # Print the output array\n",
    "# print(output_array)\n",
    "# output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# msent = preprocess_text(msent)\n",
    "# print(msent)\n",
    "# msent = msent.split(\" \")\n",
    "# print(msent)\n",
    "# # msent = [w2v_model[w] for w in msent]\n",
    "# msent2 = []\n",
    "# for i in msent:\n",
    "#     try:\n",
    "#         msent2.append(w2v_model[i])\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(i)\n",
    "\n",
    "# print(msent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# msent = preprocess_text(msent)\n",
    "# print(msent)\n",
    "# msent = msent.split(\" \")\n",
    "# print(msent)\n",
    "# # msent = [w2v_model[w] for w in msent]\n",
    "# msent2 = []\n",
    "# for i in msent:\n",
    "#     try:\n",
    "#         msent2.append(w2v_model[i])\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(i)\n",
    "\n",
    "# print(msent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtokenize3(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # print(outputs.pooler_output)\n",
    "    # print(outputs.last_hidden_state)\n",
    "    # contextual_embeddings, pooled_output = outputs\n",
    "\n",
    "  \n",
    "    return outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train_embeddings = [w2v_model.wv[word] for word in X_train[title]]\n",
    "# X_test_embeddings = [w2v_model.wv[word] for word in X_test[title]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data[title] = data[title] + \" \" + data[desc] + \" \" + data[bull_pt]\n",
    "# # data[title] = data[desc]\n",
    "# data[title] = data[bull_pt] \n",
    "# # try the above thing next time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bildos 3Ply Non-Woven Fabric Disposable Surgical Dust Mask With Nose Clip Maximum Protection (Blue, Without Valve, Pack of 200) for Unisex'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[title].values[0]\n",
    "# data[bull_pt].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>PRODUCT_TYPE_ID_0</th>\n",
       "      <th>PRODUCT_TYPE_ID_1</th>\n",
       "      <th>PRODUCT_TYPE_ID_2</th>\n",
       "      <th>PRODUCT_TYPE_ID_4</th>\n",
       "      <th>PRODUCT_TYPE_ID_5</th>\n",
       "      <th>PRODUCT_TYPE_ID_6</th>\n",
       "      <th>...</th>\n",
       "      <th>PRODUCT_TYPE_ID_13248</th>\n",
       "      <th>PRODUCT_TYPE_ID_13279</th>\n",
       "      <th>PRODUCT_TYPE_ID_13280</th>\n",
       "      <th>PRODUCT_TYPE_ID_13290</th>\n",
       "      <th>PRODUCT_TYPE_ID_13294</th>\n",
       "      <th>PRODUCT_TYPE_ID_13343</th>\n",
       "      <th>PRODUCT_TYPE_ID_13346</th>\n",
       "      <th>PRODUCT_TYPE_ID_13347</th>\n",
       "      <th>PRODUCT_TYPE_ID_13368</th>\n",
       "      <th>PRODUCT_TYPE_ID_13414</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1896156</th>\n",
       "      <td>Bildos 3Ply Non-Woven Fabric Disposable Surgic...</td>\n",
       "      <td>[Care Instructions: Non Washable,Mask Has 3 La...</td>\n",
       "      <td>Face masks may also be called isolation, laser...</td>\n",
       "      <td>669.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715725</th>\n",
       "      <td>Negaor 10 PCS Interior Door Card Trim Panel Re...</td>\n",
       "      <td>[* Interior door card trim panel clips fastene...</td>\n",
       "      <td>Please check the Manufacturer Part Number and ...</td>\n",
       "      <td>314.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229576</th>\n",
       "      <td>Madden Girl Women's Domain Boot, Black Fabric,...</td>\n",
       "      <td>Chukka-inspired boot with four-eye lacing syst...</td>\n",
       "      <td>Suede wedge laceup bootie</td>\n",
       "      <td>500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670308</th>\n",
       "      <td>Patel's Velocity perfume (60ml)(pack of 1)</td>\n",
       "      <td>[Long Lasting Fragrances,Made From Real and Na...</td>\n",
       "      <td>Patel's Velocity Perfume is Long Lasting Perfu...</td>\n",
       "      <td>157.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945067</th>\n",
       "      <td>WorldCare® 1000W Car Power ply Output Socket U...</td>\n",
       "      <td>[New &amp; Imported Item,Delivers within 3 to 5 we...</td>\n",
       "      <td>WorldCare 1000W Car Power ply Output Socket US...</td>\n",
       "      <td>590.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     TITLE  \\\n",
       "1896156  Bildos 3Ply Non-Woven Fabric Disposable Surgic...   \n",
       "1715725  Negaor 10 PCS Interior Door Card Trim Panel Re...   \n",
       "229576   Madden Girl Women's Domain Boot, Black Fabric,...   \n",
       "670308          Patel's Velocity perfume (60ml)(pack of 1)   \n",
       "945067   WorldCare® 1000W Car Power ply Output Socket U...   \n",
       "\n",
       "                                             BULLET_POINTS  \\\n",
       "1896156  [Care Instructions: Non Washable,Mask Has 3 La...   \n",
       "1715725  [* Interior door card trim panel clips fastene...   \n",
       "229576   Chukka-inspired boot with four-eye lacing syst...   \n",
       "670308   [Long Lasting Fragrances,Made From Real and Na...   \n",
       "945067   [New & Imported Item,Delivers within 3 to 5 we...   \n",
       "\n",
       "                                               DESCRIPTION  PRODUCT_LENGTH  \\\n",
       "1896156  Face masks may also be called isolation, laser...          669.29   \n",
       "1715725  Please check the Manufacturer Part Number and ...          314.96   \n",
       "229576                           Suede wedge laceup bootie          500.00   \n",
       "670308   Patel's Velocity Perfume is Long Lasting Perfu...          157.48   \n",
       "945067   WorldCare 1000W Car Power ply Output Socket US...          590.55   \n",
       "\n",
       "         PRODUCT_TYPE_ID_0  PRODUCT_TYPE_ID_1  PRODUCT_TYPE_ID_2  \\\n",
       "1896156                  0                  0                  0   \n",
       "1715725                  0                  0                  0   \n",
       "229576                   0                  0                  0   \n",
       "670308                   0                  0                  0   \n",
       "945067                   0                  0                  0   \n",
       "\n",
       "         PRODUCT_TYPE_ID_4  PRODUCT_TYPE_ID_5  PRODUCT_TYPE_ID_6  ...  \\\n",
       "1896156                  0                  0                  0  ...   \n",
       "1715725                  0                  0                  0  ...   \n",
       "229576                   0                  0                  0  ...   \n",
       "670308                   0                  0                  0  ...   \n",
       "945067                   0                  0                  0  ...   \n",
       "\n",
       "         PRODUCT_TYPE_ID_13248  PRODUCT_TYPE_ID_13279  PRODUCT_TYPE_ID_13280  \\\n",
       "1896156                      0                      0                      0   \n",
       "1715725                      0                      0                      0   \n",
       "229576                       0                      0                      0   \n",
       "670308                       0                      0                      0   \n",
       "945067                       0                      0                      0   \n",
       "\n",
       "         PRODUCT_TYPE_ID_13290  PRODUCT_TYPE_ID_13294  PRODUCT_TYPE_ID_13343  \\\n",
       "1896156                      0                      0                      0   \n",
       "1715725                      0                      0                      0   \n",
       "229576                       0                      0                      0   \n",
       "670308                       0                      0                      0   \n",
       "945067                       0                      0                      0   \n",
       "\n",
       "         PRODUCT_TYPE_ID_13346  PRODUCT_TYPE_ID_13347  PRODUCT_TYPE_ID_13368  \\\n",
       "1896156                      0                      0                      0   \n",
       "1715725                      0                      0                      0   \n",
       "229576                       0                      0                      0   \n",
       "670308                       0                      0                      0   \n",
       "945067                       0                      0                      0   \n",
       "\n",
       "         PRODUCT_TYPE_ID_13414  \n",
       "1896156                      0  \n",
       "1715725                      0  \n",
       "229576                       0  \n",
       "670308                       0  \n",
       "945067                       0  \n",
       "\n",
       "[5 rows x 1622 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[title] = X_train[title] + \" \" + X_train[desc] + \" \" + X_train[bull_pt]\n",
    "# print(X_train[title].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example input text\n",
    "# input_text = X_train[title].values.tolist()\n",
    "\n",
    "# # Convert each sentence to tokens and input IDs\n",
    "# input_ids = []\n",
    "# for text in input_text:\n",
    "#     # tokens = tokenizer.tokenize(text)\n",
    "#     tokens = tokenizer.tokenize(text, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "#     ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "#     input_ids.append(ids)\n",
    "\n",
    "# # Create a `tf.data.Dataset` object to feed the input data to the model\n",
    "# input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, maxlen=128, padding='post', truncating='post')\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((input_ids,))\n",
    "# dataset = dataset.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pass the input data through the pre-trained model to get the embeddings\n",
    "# all_embeddings = []\n",
    "# for batch in dataset:\n",
    "#     with tf.device('/GPU:0'):\n",
    "#         outputs = model(batch)\n",
    "#         embeddings = outputs.pooler_output\n",
    "#         all_embeddings.append(embeddings.numpy())\n",
    "\n",
    "# # Concatenate the embeddings for all the batches\n",
    "# all_embeddings = np.concatenate(all_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pass the input data through the pre-trained model to get the embeddings\n",
    "# all_embeddings = []\n",
    "# for batch in dataset:\n",
    "#     # with tf.device('/GPU:0'):\n",
    "#     outputs = model(batch)\n",
    "#     embeddings = outputs.pooler_output\n",
    "#     all_embeddings.append(embeddings.numpy())\n",
    "\n",
    "# # Concatenate the embeddings for all the batches\n",
    "# all_embeddings = np.concatenate(all_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pass the input data through the pre-trained model to get the embeddings\n",
    "# for batch in dataset:\n",
    "#     with tf.device('/GPU:0'):\n",
    "#         outputs = model(batch)\n",
    "#         embeddings = outputs.last_hidden_state\n",
    "#         pooled_output = outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = tokenizer.tokenize(input_text)\n",
    "# input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# # Create a `tf.data.Dataset` object to feed the input data to the model\n",
    "# input_ids = tf.expand_dims(input_ids, axis=0)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((input_ids,))\n",
    "# dataset = dataset.batch(1)\n",
    "# for batch in dataset:\n",
    "#     with tf.device('/GPU:0'):\n",
    "#         outputs = model(batch)\n",
    "#         embeddings = outputs.last_hidden_state\n",
    "#         pooled_output = outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same_1 = mtokenize3(X_train[title].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding1 = X_train_embeddings[0]\n",
    "# embedding2 = all_embeddings[0]\n",
    "\n",
    "# # Compute the cosine similarity between the embeddings\n",
    "# cosine_similarities = tf.keras.losses.cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "# # Get the distance between the embeddings by subtracting the cosine similarity from 1\n",
    "# distance = 1 - cosine_similarities\n",
    "\n",
    "# print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train_embeddings = [mtokenize3(word) for word in X_train[title]]\n",
    "# X_test_embeddings = [mtokenize3(word) for word in X_test[title]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_embeddings = []\n",
    "X_test_embeddings = []\n",
    "X_whole_title = []\n",
    "X_whole_bull_pt = []\n",
    "X_whole_desc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data[title]:\n",
    "#     X_whole_title.append(mtokenize3(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[title].values)):\n",
    "    # X_whole_title.append(mtokenize3(data[title].values[i]))\n",
    "    X_whole_title.append(mtokenize3(data[title].values[i]))\n",
    "    X_whole_bull_pt.append(mtokenize3(data[bull_pt].values[i]))\n",
    "    X_whole_desc.append(mtokenize3(data[desc].values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_whole_title = np.array(X_whole_title)\n",
    "X_whole_bull_pt = np.array(X_whole_bull_pt)\n",
    "X_whole_desc = np.array(X_whole_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 768)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_whole_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the X_whole to the data\n",
    "# data['embeddings'] = X_whole\n",
    "X_whole_title = np.reshape(X_whole_title, (5000, 768))\n",
    "X_whole_bull_pt = np.reshape(X_whole_bull_pt, (5000, 768))\n",
    "X_whole_desc = np.reshape(X_whole_desc, (5000, 768))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2382</th>\n",
       "      <th>2383</th>\n",
       "      <th>2384</th>\n",
       "      <th>2385</th>\n",
       "      <th>2386</th>\n",
       "      <th>2387</th>\n",
       "      <th>2388</th>\n",
       "      <th>2389</th>\n",
       "      <th>2390</th>\n",
       "      <th>2391</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896156</td>\n",
       "      <td>Bildos 3Ply Non-Woven Fabric Disposable Surgic...</td>\n",
       "      <td>[Care Instructions: Non Washable,Mask Has 3 La...</td>\n",
       "      <td>Face masks may also be called isolation, laser...</td>\n",
       "      <td>669.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1715725</td>\n",
       "      <td>Negaor 10 PCS Interior Door Card Trim Panel Re...</td>\n",
       "      <td>[* Interior door card trim panel clips fastene...</td>\n",
       "      <td>Please check the Manufacturer Part Number and ...</td>\n",
       "      <td>314.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>229576</td>\n",
       "      <td>Madden Girl Women's Domain Boot, Black Fabric,...</td>\n",
       "      <td>Chukka-inspired boot with four-eye lacing syst...</td>\n",
       "      <td>Suede wedge laceup bootie</td>\n",
       "      <td>500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670308</td>\n",
       "      <td>Patel's Velocity perfume (60ml)(pack of 1)</td>\n",
       "      <td>[Long Lasting Fragrances,Made From Real and Na...</td>\n",
       "      <td>Patel's Velocity Perfume is Long Lasting Perfu...</td>\n",
       "      <td>157.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>945067</td>\n",
       "      <td>WorldCare® 1000W Car Power ply Output Socket U...</td>\n",
       "      <td>[New &amp; Imported Item,Delivers within 3 to 5 we...</td>\n",
       "      <td>WorldCare 1000W Car Power ply Output Socket US...</td>\n",
       "      <td>590.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>380368</td>\n",
       "      <td>Gadget Gear Vinyl Skin Back Sticker Sticker Bo...</td>\n",
       "      <td>[3d Textured Mobile Skin: GadgetGear skins dis...</td>\n",
       "      <td>A GadgetGear skin comes in the true-textured f...</td>\n",
       "      <td>700.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>688391</td>\n",
       "      <td>VICKYBEN Women's A-line Tulle Prom Formal Even...</td>\n",
       "      <td>[Fabric: High quality soft tulle, comfortable ...</td>\n",
       "      <td>&lt;b&gt; Welcome to VICKYBEN Store &lt;/b&gt; &lt;br&gt; More d...</td>\n",
       "      <td>590.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2076124</td>\n",
       "      <td>Chhaya Hanging Hook Planter Railing Flower Pla...</td>\n",
       "      <td>[Dimensions: Diameter 22 cm Height 28 cm,Set o...</td>\n",
       "      <td>Chhaya Nursery designer plastic planter pots a...</td>\n",
       "      <td>1102.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>908550</td>\n",
       "      <td>Luxocase Realme X2 Pro Carbon Fiber Leather Bl...</td>\n",
       "      <td>[Premium matte finish, stylish, and durable sn...</td>\n",
       "      <td>LUXOCASE PRESENT PRINTED DESIGNER BACK CASE CO...</td>\n",
       "      <td>511.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1562918</td>\n",
       "      <td>Harshi Hybrid Silicone Camera Protection Back ...</td>\n",
       "      <td>[Compatible with Samsung F62 Only. BEWARE OF C...</td>\n",
       "      <td>Premium Stylish Mobile Cover For Samsung F62Pr...</td>\n",
       "      <td>472.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1     \\\n",
       "0     1896156  Bildos 3Ply Non-Woven Fabric Disposable Surgic...   \n",
       "1     1715725  Negaor 10 PCS Interior Door Card Trim Panel Re...   \n",
       "2      229576  Madden Girl Women's Domain Boot, Black Fabric,...   \n",
       "3      670308         Patel's Velocity perfume (60ml)(pack of 1)   \n",
       "4      945067  WorldCare® 1000W Car Power ply Output Socket U...   \n",
       "...       ...                                                ...   \n",
       "4995   380368  Gadget Gear Vinyl Skin Back Sticker Sticker Bo...   \n",
       "4996   688391  VICKYBEN Women's A-line Tulle Prom Formal Even...   \n",
       "4997  2076124  Chhaya Hanging Hook Planter Railing Flower Pla...   \n",
       "4998   908550  Luxocase Realme X2 Pro Carbon Fiber Leather Bl...   \n",
       "4999  1562918  Harshi Hybrid Silicone Camera Protection Back ...   \n",
       "\n",
       "                                                   2     \\\n",
       "0     [Care Instructions: Non Washable,Mask Has 3 La...   \n",
       "1     [* Interior door card trim panel clips fastene...   \n",
       "2     Chukka-inspired boot with four-eye lacing syst...   \n",
       "3     [Long Lasting Fragrances,Made From Real and Na...   \n",
       "4     [New & Imported Item,Delivers within 3 to 5 we...   \n",
       "...                                                 ...   \n",
       "4995  [3d Textured Mobile Skin: GadgetGear skins dis...   \n",
       "4996  [Fabric: High quality soft tulle, comfortable ...   \n",
       "4997  [Dimensions: Diameter 22 cm Height 28 cm,Set o...   \n",
       "4998  [Premium matte finish, stylish, and durable sn...   \n",
       "4999  [Compatible with Samsung F62 Only. BEWARE OF C...   \n",
       "\n",
       "                                                   3       4     5     6     \\\n",
       "0     Face masks may also be called isolation, laser...  669.29     0     0   \n",
       "1     Please check the Manufacturer Part Number and ...  314.96     0     0   \n",
       "2                             Suede wedge laceup bootie  500.00     0     0   \n",
       "3     Patel's Velocity Perfume is Long Lasting Perfu...  157.48     0     0   \n",
       "4     WorldCare 1000W Car Power ply Output Socket US...  590.55     0     0   \n",
       "...                                                 ...     ...   ...   ...   \n",
       "4995  A GadgetGear skin comes in the true-textured f...  700.00     0     0   \n",
       "4996  <b> Welcome to VICKYBEN Store </b> <br> More d...  590.55     0     0   \n",
       "4997  Chhaya Nursery designer plastic planter pots a... 1102.36     0     0   \n",
       "4998  LUXOCASE PRESENT PRINTED DESIGNER BACK CASE CO...  511.81     0     0   \n",
       "4999  Premium Stylish Mobile Cover For Samsung F62Pr...  472.44     0     0   \n",
       "\n",
       "      7     8     9     ...  2382  2383  2384  2385  2386  2387  2388  2389  \\\n",
       "0        0     0     0  ...  0.51  0.40  0.81 -0.05 -0.15  0.23  0.56 -0.87   \n",
       "1        0     0     0  ...  0.91 -0.94  0.99  0.38 -0.84 -0.63  0.94 -0.96   \n",
       "2        0     0     0  ...  0.18 -0.52  0.97  0.79 -0.42  0.49  0.24 -0.74   \n",
       "3        0     0     0  ...  0.74 -0.42  0.97  0.52 -0.33 -0.16  0.82 -0.95   \n",
       "4        0     0     0  ...  0.54 -0.04  0.86  0.85 -0.07  0.12  0.64 -0.68   \n",
       "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "4995     0     0     0  ...  0.79 -0.83  0.99  0.20 -0.56 -0.48  0.81 -0.98   \n",
       "4996     0     0     0  ...  0.79 -0.73  0.96  0.65 -0.12 -0.11  0.82 -0.93   \n",
       "4997     0     0     0  ...  0.52 -0.82  0.99  0.68 -0.49 -0.54  0.62 -0.98   \n",
       "4998     0     0     0  ...  0.41 -0.42  0.98  0.82 -0.55  0.41  0.46 -0.90   \n",
       "4999     0     0     0  ...  0.50 -0.82  1.00  0.67 -0.60 -0.08  0.61 -0.99   \n",
       "\n",
       "      2390  2391  \n",
       "0    -0.45  0.38  \n",
       "1    -0.79  0.52  \n",
       "2    -0.73  0.87  \n",
       "3    -0.58  0.35  \n",
       "4    -0.66  0.83  \n",
       "...    ...   ...  \n",
       "4995 -0.49 -0.03  \n",
       "4996 -0.76  0.67  \n",
       "4997 -0.76  0.59  \n",
       "4998 -0.46  0.76  \n",
       "4999 -0.60  0.58  \n",
       "\n",
       "[5000 rows x 2392 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_v2 = pd.concat([data.reset_index(), pd.DataFrame(X_whole_title).reset_index()], axis=1, ignore_index=True)\n",
    "data_v2 = pd.concat([data.reset_index(), pd.DataFrame(X_whole_bull_pt).reset_index()], axis=1, ignore_index=True)\n",
    "data_v2 = pd.concat([data.reset_index(), pd.DataFrame(X_whole_desc).reset_index()], axis=1, ignore_index=True)\n",
    "data_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2392)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[desc, bull_pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v3 = data_v2.drop(columns=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>2382</th>\n",
       "      <th>2383</th>\n",
       "      <th>2384</th>\n",
       "      <th>2385</th>\n",
       "      <th>2386</th>\n",
       "      <th>2387</th>\n",
       "      <th>2388</th>\n",
       "      <th>2389</th>\n",
       "      <th>2390</th>\n",
       "      <th>2391</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>669.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>314.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>590.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    4     5     6     7     8     9     10    11    12    13    ...  2382  \\\n",
       "0 669.29     0     0     0     0     0     0     0     0     0  ...  0.51   \n",
       "1 314.96     0     0     0     0     0     0     0     0     0  ...  0.91   \n",
       "2 500.00     0     0     0     0     0     0     0     0     0  ...  0.18   \n",
       "3 157.48     0     0     0     0     0     0     0     0     0  ...  0.74   \n",
       "4 590.55     0     0     0     0     0     0     0     0     0  ...  0.54   \n",
       "\n",
       "   2383  2384  2385  2386  2387  2388  2389  2390  2391  \n",
       "0  0.40  0.81 -0.05 -0.15  0.23  0.56 -0.87 -0.45  0.38  \n",
       "1 -0.94  0.99  0.38 -0.84 -0.63  0.94 -0.96 -0.79  0.52  \n",
       "2 -0.52  0.97  0.79 -0.42  0.49  0.24 -0.74 -0.73  0.87  \n",
       "3 -0.42  0.97  0.52 -0.33 -0.16  0.82 -0.95 -0.58  0.35  \n",
       "4 -0.04  0.86  0.85 -0.07  0.12  0.64 -0.68 -0.66  0.83  \n",
       "\n",
       "[5 rows x 2388 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# data_v3 = data_v2.drop(columns=[0])\n",
    "data_v3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_name = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in X_train[title]:\n",
    "#     X_train_embeddings.append(mtokenize3(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_embeddings = np.array(X_train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in X_test[title]:\n",
    "#     X_test_embeddings.append(mtokenize3(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_embeddings = np.array(X_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data.drop([prod_len], axis=1), data[prod_len], test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_v3.drop([target_col_name], axis=1), data_v3[target_col_name], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train_embeddings[0])\n",
    "# import pickle\n",
    "# pickle.dump(X_train_embeddings, open(\"X_train_embeddings.pkl\", \"wb\"))\n",
    "# pickle.dump(X_test_embeddings, open(\"X_test_embeddings.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train_embeddings = pickle.load(open(\"X_train_embeddings.pkl\", \"rb\"))\n",
    "# X_test_embeddings = pickle.load(open(\"X_test_embeddings.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train_embeddings2 = [w2v_model.wv[word] for word in X_train[desc]]\n",
    "# X_test_embeddings2 = [w2v_model.wv[word] for word in X_test[desc]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_embeddings = np.reshape(X_train_embeddings, (800, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_embeddings = np.reshape(X_test_embeddings, (200, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf2 = pd.DataFrame(X_train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf3_mergev2 = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf3_mergev2 = mdf3_mergev2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf2 = mdf2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in mdf2.columns.values:\n",
    "#     # mdf3_mergev2[i] = mdf2[i]\n",
    "#     mdf3_mergev2 = mdf3_mergev2.join(mdf2[i])\n",
    "\n",
    "mdf3_mergev2 = pd.concat([mdf3_mergev2, mdf2], axis=1)\n",
    "mdf3_mergev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf3_mergev2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf3_mergev2 = mdf3_mergev2.drop(columns=[title, desc, bull_pt, 'index'])\n",
    "mdf3_mergev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf3_mergev1 = pd.concat([X_train, mdf2], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf3_mergev1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_final = None\n",
    "# X_test_final = None\n",
    "# # Merge embeddings with other features\n",
    "# X_train_final = pd.concat([X_train.drop([title, desc, bull_pt], axis=1), mdf2], axis=1, ignore_index=True)\n",
    "\n",
    "X_train_final = mdf3_mergev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_final = pd.concat([X_test.drop([title, desc, bull_pt], axis=1).reset_index(), pd.DataFrame(X_test_embeddings).reset_index()], axis=1, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7608\\1882317705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_final_v2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_final_v2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# X_train_final_v2[\"missing_features\"] = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# X_test_final_v2[\"missing_features\"] = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_final' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_final_v2 = X_train_final.copy()\n",
    "X_test_final_v2 = X_test_final.copy()\n",
    "\n",
    "# X_train_final_v2[\"missing_features\"] = 0\n",
    "# X_test_final_v2[\"missing_features\"] = 0\n",
    "\n",
    "# X_train_final_v2[\"missing_features2\"] = 0\n",
    "# X_test_final_v2[\"missing_features2\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_v3 = X_train_final_v2.copy()\n",
    "X_test_final_v3 = X_test_final_v2.copy()\n",
    "\n",
    "# X_train_final_v2[\"missing_features\"] = 0\n",
    "# X_test_final_v2[\"missing_features\"] = 0\n",
    "\n",
    "# X_train_final_v2[\"missing_features2\"] = 0\n",
    "# X_test_final_v2[\"missing_features2\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [range(800,1339)]\n",
    "df.drop(df.columns[cols],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_final_v2.shape)\n",
    "print(X_test_final_v2.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_v2.head()\n",
    "col_values = X_train_final_v2.columns.values\n",
    "print(col_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final_v2.head()\n",
    "col_vtest = X_test_final_v2.columns.values\n",
    "print(col_vtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_v2 = X_train_final_v2.rename(columns={\n",
    "    col_values[i] : col_vtest[i] for i in range(len(col_values))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final_v2.drop(columns=[1339, 1340], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_v2 = X_train.copy()\n",
    "X_test_final_v2 = X_test.copy()\n",
    "\n",
    "# y_train = y_train.copy()\n",
    "# y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2387)\n",
      "(1000, 2387)\n",
      "(4000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_final_v2.shape)\n",
    "print(X_test_final_v2.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>2381</th>\n",
       "      <th>2382</th>\n",
       "      <th>2383</th>\n",
       "      <th>2384</th>\n",
       "      <th>2385</th>\n",
       "      <th>2386</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  2377  \\\n",
       "4227     0     0     0     0     0     0     0     0     0     0  ...  0.55   \n",
       "4676     0     0     0     0     0     0     0     0     0     0  ...  0.05   \n",
       "800      0     0     0     0     0     0     0     0     0     0  ...  0.31   \n",
       "3671     0     0     0     0     0     0     0     0     0     0  ...  0.60   \n",
       "4193     0     0     0     0     0     0     0     0     0     0  ...  0.45   \n",
       "\n",
       "      2378  2379  2380  2381  2382  2383  2384  2385  2386  \n",
       "4227 -0.38  0.92  0.17 -0.23 -0.17  0.57 -0.92 -0.58  0.19  \n",
       "4676 -0.59  0.92  0.66 -0.55  0.66  0.27 -0.82 -0.31  0.12  \n",
       "800  -0.22  0.94  0.80 -0.34  0.15  0.40 -0.93 -0.57  0.74  \n",
       "3671 -0.83  0.97  0.62 -0.89 -0.24  0.68 -0.83 -0.59  0.23  \n",
       "4193 -0.57  0.97  0.75 -0.37  0.20  0.50 -0.95 -0.71  0.74  \n",
       "\n",
       "[5 rows x 2387 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_v2 = X_train_final_v2.drop(columns = [1])\n",
    "X_test_final_v2 = X_test_final_v2.drop(columns = [1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final_v2 = X_test_final_v2.rename(columns={\n",
    "    X_test_final_v2.columns.values[i] : i for i in range(len(X_test_final_v2.columns.values))\n",
    "})\n",
    "X_train_final_v2 = X_train_final_v2.rename(columns={\n",
    "    X_train_final_v2.columns.values[i] : i for i in range(len(X_train_final_v2.columns.values))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def score(y_test, preds):\n",
    "    error = mean_absolute_percentage_error(y_test, preds)\n",
    "    return max(0, 100*(1 - error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:22<15:30, 22.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.22351081930192174, 'Adjusted R-Squared': 1.558870815214251, 'RMSE': 6114.73812362015, 'Time taken': 22.70244812965393, 'score': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:55<38:04, 55.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7608\\237489523.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLazyRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# clf = LazyRegressor(verbose=2,ignore_warnings=False, custom_metric=None,input_features=list(X_train_final_v2.columns) ) # throws error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_final_v2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_final_v2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\lazypredict\\Supervised.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m    601\u001b[0m                     )\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                 \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         )\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             )\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         )\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnot_indices_mask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m             \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m         )\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "# # Merge embeddings with other features\n",
    "# X_train_final = pd.concat([X_train.drop([desc], axis=1), pd.DataFrame(X_train_embeddings2)], axis=1)\n",
    "# X_test_final = pd.concat([X_test.drop([desc], axis=1), pd.DataFrame(X_test_embeddings2)], axis=1)\n",
    "\n",
    "# Use Lazy Predict\n",
    "# clf = LazyClassifier(verbose=2,ignore_warnings=False, custom_metric=None)\n",
    "# clf = LazyRegressor(verbose=2,ignore_warnings=False, custom_metric=None)\n",
    "# clf = LazyRegressor(verbose=2,ignore_warnings=False, custom_metric=None)\n",
    "clf = LazyRegressor(verbose=2, ignore_warnings=False, custom_metric=score)\n",
    "# clf = LazyRegressor(verbose=2,ignore_warnings=False, custom_metric=None,input_features=list(X_train_final_v2.columns) ) # throws error\n",
    "models,predictions = clf.fit(X_train_final_v2, X_test_final_v2, y_train, y_test)\n",
    "\n",
    "print(models)\n",
    "\n",
    "# try scaling data first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lazypredict.Supervised import LazyRegressor\n",
    "# from sklearn import datasets\n",
    "# from sklearn.utils import shuffle\n",
    "# import numpy as np\n",
    "\n",
    "# boston = datasets.load_boston()\n",
    "# X, y = shuffle(boston.data, boston.target, random_state=13)\n",
    "# X = X.astype(np.float32)\n",
    "\n",
    "# offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# X_train, y_train = X[:offset], y[:offset]\n",
    "# X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "# reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "# models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_embeddings2 = [w2v_model.wv[word] for word in X_train[desc]]\n",
    "X_test_embeddings2 = [w2v_model.wv[word] for word in X_test[desc]]\n",
    "\n",
    "# Merge embeddings with other features\n",
    "X_train_final = pd.concat([X_train.drop([title], axis=1), pd.DataFrame(X_train_embeddings)], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop([title], axis=1), pd.DataFrame(X_test_embeddings)], axis=1)\n",
    "\n",
    "# Merge embeddings with other features\n",
    "X_train_final = pd.concat([X_train.drop([desc], axis=1), pd.DataFrame(X_train_embeddings2)], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop([desc], axis=1), pd.DataFrame(X_test_embeddings2)], axis=1)\n",
    "\n",
    "# Use Lazy Predict\n",
    "clf = LazyClassifier(verbose=2,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train_final, X_test_final, y_train, y_test)\n",
    "\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtokenize2(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "    outputs = model(inputs)\n",
    "  \n",
    "    return outputs[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to outputs.last_hidden_state, TFBaseModelOutputWithPoolingAndCrossAttentions also contains a pooler_output tensor, which is a fixed-size vector that summarizes the entire input sequence and is often used as input to a downstream task-specific classifier. The size of this pooler_output tensor is typically equal to the hidden size of the pre-trained model. Additionally, if the pre-trained model has cross-attention layers, TFBaseModelOutputWithPoolingAndCrossAttentions may also contain cross-attention tensors that represent the attention weights applied to the input sequence from other sequences in the batch.\n",
    "\n",
    "In the case of the TFBaseModelOutputWithPoolingAndCrossAttentions class from the Hugging Face Transformers library, outputs.last_hidden_state refers to a tensor containing the contextualized embeddings of each token in the input sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtokenize(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='tf', max_length=512)\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "\n",
    "    output_array = outputs[0].numpy()\n",
    "\n",
    "    # Flatten and reshape the output array to match sklearn input format\n",
    "    output_array = output_array.flatten().reshape(1, -1)\n",
    "    \n",
    "    # return outputs[0]\n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for i in range(3):\n",
    "    mtest = X_train[title].values[i] + \" \" + X_train[desc].values[i] + \" \" + X_train[bull_pt].values[i]\n",
    "    texts.append(mtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in texts:\n",
    "    # print(mtokenize(i))\n",
    "    # print(mtokenize(i).shape)\n",
    "\n",
    "    # print(mtokenize2(i))\n",
    "    # print(mtokenize2(i).shape)\n",
    "\n",
    "    print(mtokenize3(i))\n",
    "    print(mtokenize3(i).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtokenize(\"hansco this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtokenize(\"hansco this\")[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lazypredict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 13756.648203570148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load data into a pandas DataFrame\n",
    "# data = pd.read_csv('data.csv')\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "# X = data.drop('target_variable', axis=1)\n",
    "# y = data['target_variable']\n",
    "\n",
    "# Split data into training and test sets\n",
    "# X_train1, X_test2, y_train3, y_test4 = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create a RandomForestRegressor object with default hyperparameters\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "rf_regressor.fit(X_train_final_v2, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_regressor.predict(X_test_final_v2)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "# shot in the dark is not going to work. maybe first visualize the data and see if there is a pattern\n",
    "# let's see what you can understand from it\n",
    "\n",
    "# that's off, very off\n",
    "# map it maybe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
