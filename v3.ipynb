{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\panch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\panch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\panch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dfhelper as dfh\n",
    "import text_preproc as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2249698, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1925202</td>\n",
       "      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n",
       "      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650</td>\n",
       "      <td>2125.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2673191</td>\n",
       "      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n",
       "      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2755</td>\n",
       "      <td>393.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
       "      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n",
       "      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
       "      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n",
       "      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283658</td>\n",
       "      <td>The United Empire Loyalists: A Chronicle of th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6112</td>\n",
       "      <td>598.424000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID                                              TITLE  \\\n",
       "0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n",
       "1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n",
       "2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
       "3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
       "4      283658  The United Empire Loyalists: A Chronicle of th...   \n",
       "\n",
       "                                       BULLET_POINTS  \\\n",
       "0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n",
       "1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n",
       "2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n",
       "3  [Made By 95%cotton and 5% Lycra which gives yo...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "0                                                NaN             1650   \n",
       "1                                                NaN             2755   \n",
       "2  Specifications: Color: Red, Material: Aluminiu...             7537   \n",
       "3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n",
       "4                                                NaN             6112   \n",
       "\n",
       "   PRODUCT_LENGTH  \n",
       "0     2125.980000  \n",
       "1      393.700000  \n",
       "2      748.031495  \n",
       "3      787.401574  \n",
       "4      598.424000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.DESCRIPTION.apply(len)>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
       "      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n",
       "      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
       "      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n",
       "      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2152929</td>\n",
       "      <td>HINS Metal Bucket Shape Plant Pot for Indoor &amp;...</td>\n",
       "      <td>[Simple and elegant, great for displaying indo...</td>\n",
       "      <td>HINS Brings you the most Elegant Looking Pot w...</td>\n",
       "      <td>5725</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2026580</td>\n",
       "      <td>Delavala Self Adhesive Kitchen Backsplash Wall...</td>\n",
       "      <td>[HIGH QUALITY PVC MATERIAL: The kitchen alumin...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Aluminum Foil Stickers-good kitchen...</td>\n",
       "      <td>6030</td>\n",
       "      <td>984.251967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2998633</td>\n",
       "      <td>Hexwell Essential oil for Home Fragrance Oil A...</td>\n",
       "      <td>[100% Pure And Natural Essential Oil Or Fragra...</td>\n",
       "      <td>Transform your home, workplace or hotel room i...</td>\n",
       "      <td>8201</td>\n",
       "      <td>393.700787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249685</th>\n",
       "      <td>2841950</td>\n",
       "      <td>A &amp; H ENTERPRISES Serving Bowls with lids Set ...</td>\n",
       "      <td>[Sales Package Includes :- Set of 4 pc Serving...</td>\n",
       "      <td>We provides you Stainless Steel Serving Bowls ...</td>\n",
       "      <td>3485</td>\n",
       "      <td>787.401574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249686</th>\n",
       "      <td>1898841</td>\n",
       "      <td>Cocomii Holographic iPhone 11 Pro Case - Holog...</td>\n",
       "      <td>[COCOMII - UNIQUE, STYLISH, QUALITY: This beau...</td>\n",
       "      <td>&lt;b&gt;COCOMII&lt;/b&gt;&lt;br&gt;&lt;br&gt;We transform amazing ide...</td>\n",
       "      <td>12556</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249689</th>\n",
       "      <td>1616561</td>\n",
       "      <td>Have It Tall Men's Curved Hem Long Drop Tail T...</td>\n",
       "      <td>[Light Weight 65% Polyester/ 35% Ring Spun Cot...</td>\n",
       "      <td>This extra long Tall t-Shirt will be your favo...</td>\n",
       "      <td>2879</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249694</th>\n",
       "      <td>2766635</td>\n",
       "      <td>(3PCS) Goose Game Cute Cartoon Enamel Pins, Fu...</td>\n",
       "      <td>[❤ [Inspiration] Inspired by the Untitled Goos...</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;[Brand]: &lt;/b&gt;XVIEONR&lt;/p&gt; &lt;p&gt;&lt;br&gt;&lt;/p&gt; &lt;p&gt;...</td>\n",
       "      <td>3413</td>\n",
       "      <td>125.984252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249695</th>\n",
       "      <td>1987786</td>\n",
       "      <td>Kangroo Sweep Movement Printed Wooden Wall Clo...</td>\n",
       "      <td>[Dial size: 12 inches in diameter,Big, clear r...</td>\n",
       "      <td>Wall Clocks Are Very Attractive In Looks And E...</td>\n",
       "      <td>1574</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929273 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRODUCT_ID                                              TITLE  \\\n",
       "2           2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
       "3           1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
       "5           2152929  HINS Metal Bucket Shape Plant Pot for Indoor &...   \n",
       "7           2026580  Delavala Self Adhesive Kitchen Backsplash Wall...   \n",
       "9           2998633  Hexwell Essential oil for Home Fragrance Oil A...   \n",
       "...             ...                                                ...   \n",
       "2249685     2841950  A & H ENTERPRISES Serving Bowls with lids Set ...   \n",
       "2249686     1898841  Cocomii Holographic iPhone 11 Pro Case - Holog...   \n",
       "2249689     1616561  Have It Tall Men's Curved Hem Long Drop Tail T...   \n",
       "2249694     2766635  (3PCS) Goose Game Cute Cartoon Enamel Pins, Fu...   \n",
       "2249695     1987786  Kangroo Sweep Movement Printed Wooden Wall Clo...   \n",
       "\n",
       "                                             BULLET_POINTS  \\\n",
       "2        [Loud Dual Tone Trumpet Horn, Compatible With ...   \n",
       "3        [Made By 95%cotton and 5% Lycra which gives yo...   \n",
       "5        [Simple and elegant, great for displaying indo...   \n",
       "7        [HIGH QUALITY PVC MATERIAL: The kitchen alumin...   \n",
       "9        [100% Pure And Natural Essential Oil Or Fragra...   \n",
       "...                                                    ...   \n",
       "2249685  [Sales Package Includes :- Set of 4 pc Serving...   \n",
       "2249686  [COCOMII - UNIQUE, STYLISH, QUALITY: This beau...   \n",
       "2249689  [Light Weight 65% Polyester/ 35% Ring Spun Cot...   \n",
       "2249694  [❤ [Inspiration] Inspired by the Untitled Goos...   \n",
       "2249695  [Dial size: 12 inches in diameter,Big, clear r...   \n",
       "\n",
       "                                               DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "2        Specifications: Color: Red, Material: Aluminiu...             7537   \n",
       "3        AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n",
       "5        HINS Brings you the most Elegant Looking Pot w...             5725   \n",
       "7        <p><strong>Aluminum Foil Stickers-good kitchen...             6030   \n",
       "9        Transform your home, workplace or hotel room i...             8201   \n",
       "...                                                    ...              ...   \n",
       "2249685  We provides you Stainless Steel Serving Bowls ...             3485   \n",
       "2249686  <b>COCOMII</b><br><br>We transform amazing ide...            12556   \n",
       "2249689  This extra long Tall t-Shirt will be your favo...             2879   \n",
       "2249694  <p><b>[Brand]: </b>XVIEONR</p> <p><br></p> <p>...             3413   \n",
       "2249695  Wall Clocks Are Very Attractive In Looks And E...             1574   \n",
       "\n",
       "         PRODUCT_LENGTH  \n",
       "2            748.031495  \n",
       "3            787.401574  \n",
       "5            950.000000  \n",
       "7            984.251967  \n",
       "9            393.700787  \n",
       "...                 ...  \n",
       "2249685      787.401574  \n",
       "2249686      600.000000  \n",
       "2249689     1200.000000  \n",
       "2249694      125.984252  \n",
       "2249695     1200.000000  \n",
       "\n",
       "[929273 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
       "      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n",
       "      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
       "      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n",
       "      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2152929</td>\n",
       "      <td>HINS Metal Bucket Shape Plant Pot for Indoor &amp;...</td>\n",
       "      <td>[Simple and elegant, great for displaying indo...</td>\n",
       "      <td>HINS Brings you the most Elegant Looking Pot w...</td>\n",
       "      <td>5725</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2026580</td>\n",
       "      <td>Delavala Self Adhesive Kitchen Backsplash Wall...</td>\n",
       "      <td>[HIGH QUALITY PVC MATERIAL: The kitchen alumin...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Aluminum Foil Stickers-good kitchen...</td>\n",
       "      <td>6030</td>\n",
       "      <td>984.251967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2998633</td>\n",
       "      <td>Hexwell Essential oil for Home Fragrance Oil A...</td>\n",
       "      <td>[100% Pure And Natural Essential Oil Or Fragra...</td>\n",
       "      <td>Transform your home, workplace or hotel room i...</td>\n",
       "      <td>8201</td>\n",
       "      <td>393.700787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249685</th>\n",
       "      <td>2841950</td>\n",
       "      <td>A &amp; H ENTERPRISES Serving Bowls with lids Set ...</td>\n",
       "      <td>[Sales Package Includes :- Set of 4 pc Serving...</td>\n",
       "      <td>We provides you Stainless Steel Serving Bowls ...</td>\n",
       "      <td>3485</td>\n",
       "      <td>787.401574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249686</th>\n",
       "      <td>1898841</td>\n",
       "      <td>Cocomii Holographic iPhone 11 Pro Case - Holog...</td>\n",
       "      <td>[COCOMII - UNIQUE, STYLISH, QUALITY: This beau...</td>\n",
       "      <td>&lt;b&gt;COCOMII&lt;/b&gt;&lt;br&gt;&lt;br&gt;We transform amazing ide...</td>\n",
       "      <td>12556</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249689</th>\n",
       "      <td>1616561</td>\n",
       "      <td>Have It Tall Men's Curved Hem Long Drop Tail T...</td>\n",
       "      <td>[Light Weight 65% Polyester/ 35% Ring Spun Cot...</td>\n",
       "      <td>This extra long Tall t-Shirt will be your favo...</td>\n",
       "      <td>2879</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249694</th>\n",
       "      <td>2766635</td>\n",
       "      <td>(3PCS) Goose Game Cute Cartoon Enamel Pins, Fu...</td>\n",
       "      <td>[❤ [Inspiration] Inspired by the Untitled Goos...</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;[Brand]: &lt;/b&gt;XVIEONR&lt;/p&gt; &lt;p&gt;&lt;br&gt;&lt;/p&gt; &lt;p&gt;...</td>\n",
       "      <td>3413</td>\n",
       "      <td>125.984252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249695</th>\n",
       "      <td>1987786</td>\n",
       "      <td>Kangroo Sweep Movement Printed Wooden Wall Clo...</td>\n",
       "      <td>[Dial size: 12 inches in diameter,Big, clear r...</td>\n",
       "      <td>Wall Clocks Are Very Attractive In Looks And E...</td>\n",
       "      <td>1574</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929273 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRODUCT_ID                                              TITLE  \\\n",
       "2           2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
       "3           1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
       "5           2152929  HINS Metal Bucket Shape Plant Pot for Indoor &...   \n",
       "7           2026580  Delavala Self Adhesive Kitchen Backsplash Wall...   \n",
       "9           2998633  Hexwell Essential oil for Home Fragrance Oil A...   \n",
       "...             ...                                                ...   \n",
       "2249685     2841950  A & H ENTERPRISES Serving Bowls with lids Set ...   \n",
       "2249686     1898841  Cocomii Holographic iPhone 11 Pro Case - Holog...   \n",
       "2249689     1616561  Have It Tall Men's Curved Hem Long Drop Tail T...   \n",
       "2249694     2766635  (3PCS) Goose Game Cute Cartoon Enamel Pins, Fu...   \n",
       "2249695     1987786  Kangroo Sweep Movement Printed Wooden Wall Clo...   \n",
       "\n",
       "                                             BULLET_POINTS  \\\n",
       "2        [Loud Dual Tone Trumpet Horn, Compatible With ...   \n",
       "3        [Made By 95%cotton and 5% Lycra which gives yo...   \n",
       "5        [Simple and elegant, great for displaying indo...   \n",
       "7        [HIGH QUALITY PVC MATERIAL: The kitchen alumin...   \n",
       "9        [100% Pure And Natural Essential Oil Or Fragra...   \n",
       "...                                                    ...   \n",
       "2249685  [Sales Package Includes :- Set of 4 pc Serving...   \n",
       "2249686  [COCOMII - UNIQUE, STYLISH, QUALITY: This beau...   \n",
       "2249689  [Light Weight 65% Polyester/ 35% Ring Spun Cot...   \n",
       "2249694  [❤ [Inspiration] Inspired by the Untitled Goos...   \n",
       "2249695  [Dial size: 12 inches in diameter,Big, clear r...   \n",
       "\n",
       "                                               DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "2        Specifications: Color: Red, Material: Aluminiu...             7537   \n",
       "3        AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n",
       "5        HINS Brings you the most Elegant Looking Pot w...             5725   \n",
       "7        <p><strong>Aluminum Foil Stickers-good kitchen...             6030   \n",
       "9        Transform your home, workplace or hotel room i...             8201   \n",
       "...                                                    ...              ...   \n",
       "2249685  We provides you Stainless Steel Serving Bowls ...             3485   \n",
       "2249686  <b>COCOMII</b><br><br>We transform amazing ide...            12556   \n",
       "2249689  This extra long Tall t-Shirt will be your favo...             2879   \n",
       "2249694  <p><b>[Brand]: </b>XVIEONR</p> <p><br></p> <p>...             3413   \n",
       "2249695  Wall Clocks Are Very Attractive In Looks And E...             1574   \n",
       "\n",
       "         PRODUCT_LENGTH  \n",
       "2            748.031495  \n",
       "3            787.401574  \n",
       "5            950.000000  \n",
       "7            984.251967  \n",
       "9            393.700787  \n",
       "...                 ...  \n",
       "2249685      787.401574  \n",
       "2249686      600.000000  \n",
       "2249689     1200.000000  \n",
       "2249694      125.984252  \n",
       "2249695     1200.000000  \n",
       "\n",
       "[929273 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_provider(x):\n",
    "    print(x)\n",
    "    return x.count(\">\")>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = cdf[cdf.DESCRIPTION.apply(lambda x: x.count(\">\") == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
       "      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n",
       "      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
       "      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n",
       "      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2152929</td>\n",
       "      <td>HINS Metal Bucket Shape Plant Pot for Indoor &amp;...</td>\n",
       "      <td>[Simple and elegant, great for displaying indo...</td>\n",
       "      <td>HINS Brings you the most Elegant Looking Pot w...</td>\n",
       "      <td>5725</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2998633</td>\n",
       "      <td>Hexwell Essential oil for Home Fragrance Oil A...</td>\n",
       "      <td>[100% Pure And Natural Essential Oil Or Fragra...</td>\n",
       "      <td>Transform your home, workplace or hotel room i...</td>\n",
       "      <td>8201</td>\n",
       "      <td>393.700787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2790448</td>\n",
       "      <td>SEGOVIA Single Walled Stainless Steel Sports| ...</td>\n",
       "      <td>[Segovia bottle consists of stainless steel wh...</td>\n",
       "      <td>Segovia bottle consists of stainless steel whi...</td>\n",
       "      <td>1273</td>\n",
       "      <td>314.960630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRODUCT_ID                                              TITLE  \\\n",
       "2      2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
       "3      1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
       "5      2152929  HINS Metal Bucket Shape Plant Pot for Indoor &...   \n",
       "9      2998633  Hexwell Essential oil for Home Fragrance Oil A...   \n",
       "14     2790448  SEGOVIA Single Walled Stainless Steel Sports| ...   \n",
       "\n",
       "                                        BULLET_POINTS  \\\n",
       "2   [Loud Dual Tone Trumpet Horn, Compatible With ...   \n",
       "3   [Made By 95%cotton and 5% Lycra which gives yo...   \n",
       "5   [Simple and elegant, great for displaying indo...   \n",
       "9   [100% Pure And Natural Essential Oil Or Fragra...   \n",
       "14  [Segovia bottle consists of stainless steel wh...   \n",
       "\n",
       "                                          DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "2   Specifications: Color: Red, Material: Aluminiu...             7537   \n",
       "3   AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n",
       "5   HINS Brings you the most Elegant Looking Pot w...             5725   \n",
       "9   Transform your home, workplace or hotel room i...             8201   \n",
       "14  Segovia bottle consists of stainless steel whi...             1273   \n",
       "\n",
       "    PRODUCT_LENGTH  \n",
       "2       748.031495  \n",
       "3       787.401574  \n",
       "5       950.000000  \n",
       "9       393.700787  \n",
       "14      314.960630  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620251, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf2 = cdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf2 = cdf2.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf2 = cdf2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import CamembertTokenizer\n",
    "# tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "\n",
    "encoded_corpus = tokenizer(text=cdf2.DESCRIPTION.tolist(),\n",
    "                            add_special_tokens=True,\n",
    "                            padding='max_length',\n",
    "                            truncation='longest_first',\n",
    "                            max_length=300,\n",
    "                            return_attention_mask=True)\n",
    "input_ids = encoded_corpus['input_ids']\n",
    "attention_mask = encoded_corpus['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 104, 1071, 7873, 6, 10, 1518, 157, 684, 13, 63, 27838, 81, 720, 19819, 539, 34, 1146, 5, 5184, 9, 1690, 658, 1397, 9412, 6344, 785, 6, 14293, 8, 15835, 806, 7, 666, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def filter_long_descriptions(tokenizer, descriptions, max_len):\n",
    "    indices = []\n",
    "    lengths = tokenizer(descriptions, padding=False, \n",
    "                     truncation=False, return_length=True)['length']\n",
    "    for i in range(len(descriptions)):\n",
    "        if lengths[i] <= max_len-2:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "short_descriptions = filter_long_descriptions(tokenizer, \n",
    "                               cdf2.DESCRIPTION.tolist(), 300)\n",
    "input_ids = np.array(input_ids)[short_descriptions]\n",
    "attention_mask = np.array(attention_mask)[short_descriptions]\n",
    "labels = cdf2.PRODUCT_LENGTH.to_numpy()[short_descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.1\n",
    "seed = 42\n",
    "train_inputs, test_inputs, train_labels, test_labels = \\\n",
    "            train_test_split(input_ids, labels, test_size=test_size, \n",
    "                             random_state=seed)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_mask, \n",
    "                                        labels, test_size=test_size, \n",
    "                                        random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "price_scaler = StandardScaler()\n",
    "price_scaler.fit(train_labels.reshape(-1, 1))\n",
    "train_labels = price_scaler.transform(train_labels.reshape(-1, 1))\n",
    "test_labels = price_scaler.transform(test_labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages (from torch) (4.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "batch_size = 32\n",
    "def create_dataloaders(inputs, masks, labels, batch_size):\n",
    "    input_tensor = torch.tensor(inputs)\n",
    "    mask_tensor = torch.tensor(masks)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    dataset = TensorDataset(input_tensor, mask_tensor, \n",
    "                            labels_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            shuffle=True)\n",
    "    return dataloader\n",
    "train_dataloader = create_dataloaders(train_inputs, train_masks, \n",
    "                                      train_labels, batch_size)\n",
    "test_dataloader = create_dataloaders(test_inputs, test_masks, \n",
    "                                     test_labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# batch_size = 32\n",
    "# def create_dataloaders(inputs, masks, labels, batch_size):\n",
    "#     input_tensor = torch.tensor(inputs)\n",
    "#     mask_tensor = torch.tensor(masks)\n",
    "#     labels_tensor = torch.tensor(labels)\n",
    "#     dataset = TensorDataset(input_tensor, mask_tensor, \n",
    "#                             labels_tensor)\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "#                             shuffle=True)\n",
    "#     return dataloader\n",
    "# train_dataloader = create_dataloaders(train_inputs, train_masks, \n",
    "#                                       train_labels, batch_size)\n",
    "# test_dataloader = create_dataloaders(test_inputs, test_masks, \n",
    "#                                      test_labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# from transformers import RobertaModel\n",
    "\n",
    "# class RobertaRegressor(nn.Module):\n",
    "    \n",
    "#     def __init__(self, drop_rate=0.2, freeze_camembert=False):\n",
    "        \n",
    "#         super(CamembertRegressor, self).__init__()\n",
    "#         D_in, D_out = 768, 1\n",
    "        \n",
    "#         self.camembert = \\\n",
    "#                    CamembertModel.from_pretrained('camembert-base')\n",
    "#         self.regressor = nn.Sequential(\n",
    "#             nn.Dropout(drop_rate),\n",
    "#             nn.Linear(D_in, D_out))\n",
    "#     def forward(self, input_ids, attention_masks):\n",
    "        \n",
    "#         outputs = self.camembert(input_ids, attention_masks)\n",
    "#         class_label_output = outputs[1]\n",
    "#         outputs = self.regressor(class_label_output)\n",
    "#         return outputs\n",
    "# model = CamembertRegressor(drop_rate=0.2)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaModel\n",
    "\n",
    "class RobertaRegressor(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(RobertaRegressor, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(self.roberta.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)[1]\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = RobertaRegressor(dropout_prob=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaRegressor(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU.\")\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=5e-5,\n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 5\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,       \n",
    "                 num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-----\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17468\\1258480536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m model = train(model, optimizer, scheduler, loss_function, epochs, \n\u001b[1;32m---> 25\u001b[1;33m               train_dataloader, device, clip_value=2)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17468\\1258480536.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, scheduler, loss_function, epochs, train_dataloader, device, clip_value)\u001b[0m\n\u001b[0;32m     16\u001b[0m                              batch_labels.squeeze())\n\u001b[0;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mclip_grad_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\panch\\anaconda3\\envs\\tfodv2\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.clip_grad import clip_grad_norm\n",
    "def train(model, optimizer, scheduler, loss_function, epochs,       \n",
    "          train_dataloader, device, clip_value=2):\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        print(\"-----\")\n",
    "        best_loss = 1e10\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader): \n",
    "            print(step)  \n",
    "            batch_inputs, batch_masks, batch_labels = \\\n",
    "                               tuple(b.to(device) for b in batch)\n",
    "            model.zero_grad()\n",
    "            outputs = model(batch_inputs, batch_masks)           \n",
    "            loss = loss_function(outputs.squeeze(), \n",
    "                             batch_labels.squeeze())\n",
    "            loss = loss.float()\n",
    "            loss.backward()\n",
    "            clip_grad_norm(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "                \n",
    "    return model\n",
    "model = train(model, optimizer, scheduler, loss_function, epochs, \n",
    "              train_dataloader, device, clip_value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
